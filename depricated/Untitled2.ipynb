{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6808f078-8428-488f-a6b4-c5516564f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cupy\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numba import cuda, jit\n",
    "\n",
    "from dask import delayed, compute\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "from cuml.experimental.preprocessing import  StandardScaler\n",
    "from cuml import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "010724bf-3ebc-4dfb-a06e-4908e3c88172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path and sitename\n",
    "site = 'TALL'\n",
    "path = '/rapids/notebooks/data'\n",
    "data = f'{path}/hyperspectral/DP3.30006.001/2021/FullSite/D08/2021_TALL_6/L3/Spectrometer/Reflectance'\n",
    "\n",
    "# find the filenames\n",
    "files = [os.path.join(data, f) for f in os.listdir(data) if '.h5' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37a8fa0-76a9-444f-8466-42bad15a211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_list():\n",
    "    '''excludes bands with H2O or CO2 absorption'''\n",
    "    good_bands = np.hstack([\n",
    "        np.arange(0, 188 + 1),\n",
    "        np.arange(211, 269 + 1),\n",
    "        np.arange(316, 425 + 1)\n",
    "    ])\n",
    "    \n",
    "    return good_bands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0101fd6b-c091-4375-9aa9-5b044a7c6e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def sample_from_file(fname, size):\n",
    "    '''samples from file'''\n",
    "    \n",
    "    # open the file\n",
    "    f = h5py.File(fname, 'r')\n",
    "\n",
    "    # get the within reflectance as np array\n",
    "    refl_array = np.array(np.rot90(f[site]['Reflectance']['Reflectance_Data']))\n",
    "\n",
    "    # drop bad bands from refl_array\n",
    "    refl_array = refl_array[:, :, band_list()]\n",
    "\n",
    "    # get shape of wavelenght dimension\n",
    "    wl = refl_array.shape[2]\n",
    "\n",
    "    # reshape\n",
    "    flat_refl = refl_array.reshape(-1, wl)\n",
    "\n",
    "    # drop nulls\n",
    "    flat_refl = flat_refl[\n",
    "    (~np.any(flat_refl == -9999, axis=1)) &\n",
    "    (~np.any(np.isnan(flat_refl), axis=1))]\n",
    "\n",
    "    # get random sample indices\n",
    "    sample_idx = random.sample(range(flat_refl.shape[0]), int(flat_refl.shape[0] * size))\n",
    "\n",
    "    # return sample\n",
    "    return flat_refl[sample_idx, :]\n",
    "    \n",
    "\n",
    "def sample_from_all(files, size):\n",
    "    '''\n",
    "    Returns a np array of samples of shape (N, wl) where N is\n",
    "    the number of samples and wl is the length of the wavelength\n",
    "    dimension.\n",
    "    \n",
    "    args:\n",
    "        files    - list of full paths to netcdf4 files to be used. \n",
    "        size     - fraction of data to be used.\n",
    "    '''\n",
    "    # empty list for samples\n",
    "    samples = []\n",
    "    \n",
    "    for fname in files:\n",
    "        samples.append(sample_from_file(fname, size))\n",
    "        \n",
    "    with ProgressBar():\n",
    "        sample = np.vstack(compute(*samples))\n",
    "        \n",
    "    return sample\n",
    "\n",
    "\n",
    "def plot_pca_var(pca):\n",
    "    '''plots explained variance by PCA component'''\n",
    "    \n",
    "    # make fig\n",
    "    plt.figure(figsize=(10,4));\n",
    "\n",
    "    # plot\n",
    "    plt.plot(range(1, 359),\n",
    "             cupy.asnumpy(pca.explained_variance_ratio_.cumsum()),\n",
    "             marker='o',\n",
    "             linestyle='--');\n",
    "    \n",
    "    # details\n",
    "    plt.title('Explained Variance by Number of Components');\n",
    "    plt.xlabel('Components');\n",
    "    plt.ylabel('Cumulative explained Var');\n",
    "    plt.xlim(0, 20);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "435e51f5-ccdd-4a5d-9721-3822d30b3ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  4min  9.2s\n"
     ]
    }
   ],
   "source": [
    "size = 1 / 500\n",
    "sample = sample_from_all(files, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2a3c236-00b6-4fae-b4af-19f24c8ec4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W] [19:33:14.848321] Warning(`fit`): As of v0.16, PCA invoked without an n_components argument defauts to using min(n_samples, n_features) rather than 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PCA()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = cupy.array(sample)\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler().fit(sample)\n",
    "scaled = scaler.transform(sample)\n",
    "\n",
    "# instantiate the PCA thingy\n",
    "pca = PCA()\n",
    "\n",
    "# fit the pca model\n",
    "pca.fit(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57915ef8-d669-4811-b634-b6a9bdbc7f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot_pca_var(pca)\n",
    "type(cupy.asnumpy(pca.explained_variance_ratio_.cumsum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4fb6cc66-56de-484d-be33-bbed9dad7710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_h5_return_dict(fname):\n",
    "    '''reads'''  \n",
    "\n",
    "    # open the file\n",
    "    f = h5py.File(fname, 'r')\n",
    "    \n",
    "    # seperate out reflectance\n",
    "    refl = f[site]['Reflectance']\n",
    "\n",
    "    # get the actual data within reflectance as cupy array\n",
    "    refl_array = cupy.array(np.rot90(refl['Reflectance_Data']))\n",
    "    \n",
    "    # drop bad bands from refl_array\n",
    "    refl_array = refl_array[:, :, band_list()]\n",
    "    \n",
    "    # get wavelength info\n",
    "    wavelengths = np.array(refl['Metadata']['Spectral_Data']['Wavelength'])\n",
    "    \n",
    "    # drop bad bands from wavelength\n",
    "    wavelengths = wavelengths[band_list()]\n",
    "    \n",
    "    # bag geographic info\n",
    "    epsg = refl['Metadata']['Coordinate_System']['EPSG Code'][()].decode(\"utf-8\")\n",
    "    epsg = f'EPSG:{epsg}'\n",
    "    crs_info = refl['Metadata']['Coordinate_System']['Map_Info'][()].decode(\"utf-8\").split(',')\n",
    "    utm_zone = int(crs_info[7])\n",
    "\n",
    "    xmin = float(crs_info[3])\n",
    "    ymax = float(crs_info[4])\n",
    "    res = (float(crs_info[5]), float(crs_info[6]))\n",
    "\n",
    "    xmax = xmin + (refl_array.shape[1] * res[0]) \n",
    "    ymin = ymax - (refl_array.shape[0] * res[1])\n",
    "\n",
    "    extent = (xmin, xmax, ymin, ymax) \n",
    "\n",
    "    # find and add scale factor and data ignore value as attrs\n",
    "    scale_factor = refl['Reflectance_Data'].attrs['Scale_Factor']\n",
    "    no_data_value = refl['Reflectance_Data'].attrs['Data_Ignore_Value']\n",
    "    \n",
    "    \n",
    "    \n",
    "    return(refl_array)\n",
    "    \n",
    "    \n",
    "a = read_h5to_xarray_with_spectral_indices(files[0])                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceb2067-6a8a-473e-93f9-047fbae1a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # get wavelength info\n",
    "    wavelengths = refl['Metadata']['Spectral_Data']['Wavelength']\n",
    "\n",
    "    # bag geographic info\n",
    "    epsg = refl['Metadata']['Coordinate_System']['EPSG Code'][()].decode(\"utf-8\")\n",
    "    epsg = f'EPSG:{epsg}'\n",
    "    crs_info = refl['Metadata']['Coordinate_System']['Map_Info'][()].decode(\"utf-8\").split(',')\n",
    "    utm_zone = int(crs_info[7])\n",
    "\n",
    "    xmin = float(crs_info[3])\n",
    "    ymax = float(crs_info[4])\n",
    "    res = (float(crs_info[5]), float(crs_info[6]))\n",
    "\n",
    "    xmax = xmin + (refl_array.shape[1] * res[0]) \n",
    "    ymin = ymax - (refl_array.shape[0] * res[1])\n",
    "\n",
    "    extent = (xmin, xmax, ymin, ymax) \n",
    "\n",
    "    # find and add scale factor and data ignore value as attrs\n",
    "    scale_factor = refl['Reflectance_Data'].attrs['Scale_Factor']\n",
    "    no_data_value = refl['Reflectance_Data'].attrs['Data_Ignore_Value']\n",
    "    d_all.attrs = {'scale_factor': scale_factor, 'no_data_value': no_data_value}\n",
    "    \n",
    "    # select only good bands\n",
    "    d_all =  d_all.isel(wl=band_list()[0]).chunk({'x':'auto','y':'auto','wl':-1})\n",
    "    \n",
    "    # calculate the spectral indices and add to dataset\n",
    "    ndvi = ((d_all.reflectance.sel(wl=858.6,\n",
    "                                   method='nearest') -\n",
    "             d_all.reflectance.sel(wl=648.2,\n",
    "                                   method='nearest')) /\n",
    "            (d_all.reflectance.sel(wl=858.6,\n",
    "                                   method='nearest') +\n",
    "             d_all.reflectance.sel(wl=648.2,\n",
    "                                   method='nearest'))\n",
    "           ).assign_coords(index='ndvi').expand_dims('index')\n",
    "\n",
    "\n",
    "    cai = ((0.5 *\n",
    "            (d_all.reflectance.sel(wl=2000,\n",
    "                                   method='nearest') /\n",
    "             10000.0 +\n",
    "             d_all.reflectance.sel(wl=2200,\n",
    "                                   method='nearest') /\n",
    "             10000.0)) - d_all.reflectance.sel(wl=2100.0,\n",
    "                                              method='nearest') /\n",
    "          10000.0).drop('wl').assign_coords(index='cai').expand_dims('index')\n",
    "\n",
    "\n",
    "    ndli = ((np.log(1. /\n",
    "                           (d_all.reflectance.sel(wl=1754.,\n",
    "                                                  method='nearest') /\n",
    "                            10000.0)) -\n",
    "             np.log(1.0 /\n",
    "                           (d_all.reflectance.sel(wl=1680.0,\n",
    "                                                  method='nearest') /\n",
    "                          10000.0))) /\n",
    "            (np.log(d_all.reflectance.sel(wl=1754.0,\n",
    "                                                 method='nearest') /\n",
    "                           10000.0) +\n",
    "             np.log(d_all.reflectance.sel(wl=1680,\n",
    "                                               method='nearest') /\n",
    "                           10000.0))).assign_coords(index='ndli').expand_dims('index')\n",
    "\n",
    "\n",
    "    mrendvi = ((d_all.reflectance.sel(wl=750.0,\n",
    "                                      method='nearest') -\n",
    "                d_all.reflectance.sel(wl=705.0,\n",
    "                                      method='nearest')) /\n",
    "               (d_all.reflectance.sel(wl=750.0,\n",
    "                                      method='nearest') +\n",
    "                d_all.reflectance.sel(wl=705.0,\n",
    "                                      method='nearest') -\n",
    "                (2.0 *\n",
    "                 d_all.reflectance.sel(wl=445.0,\n",
    "                                       method='nearest')\n",
    "                )\n",
    "               )\n",
    "              ).drop('wl').assign_coords(index='mrendvi').expand_dims('index')\n",
    "\n",
    "\n",
    "    sipi = ((d_all.reflectance.sel(wl=800.0,\n",
    "                                   method='nearest') -\n",
    "             d_all.reflectance.sel(wl=445.0,\n",
    "                                   method='nearest')) /\n",
    "            (d_all.reflectance.sel(wl=800.0,\n",
    "                                   method='nearest') -\n",
    "             d_all.reflectance.sel(wl=680.0,\n",
    "                                   method='nearest')\n",
    "            )\n",
    "           ).assign_coords(index='sipi').expand_dims('index')\n",
    "\n",
    "\n",
    "    ndni = ((np.log(10000.0 /\n",
    "                           d_all.reflectance.sel(wl=1510.0,\n",
    "                                                 method='nearest')\n",
    "                          ) -\n",
    "             np.log(10000.0 /\n",
    "                           d_all.reflectance.sel(wl=1680.0,\n",
    "                                                 method='nearest')\n",
    "                          )\n",
    "            ) / \n",
    "            (np.log(10000.0 /\n",
    "                           d_all.reflectance.sel(wl=1510.0,\n",
    "                                                 method='nearest')\n",
    "                          )+np.log(10000.0 /\n",
    "                           d_all.reflectance.sel(wl=1680.0,\n",
    "                                                 method='nearest')\n",
    "                                         )\n",
    "            )\n",
    "           ).assign_coords(index='ndni').expand_dims('index')\n",
    "\n",
    "\n",
    "    cri1 = ((1.0 /\n",
    "             (d_all.reflectance.sel(wl=510.0,\n",
    "                                    method='nearest') /\n",
    "              10000.0)\n",
    "            ) -\n",
    "            (1.0 /\n",
    "             (d_all.reflectance.sel(wl=550.0,\n",
    "                                    method='nearest') /\n",
    "              10000.0)\n",
    "            )\n",
    "           ).assign_coords(index='cri1').expand_dims('index')\n",
    "\n",
    "\n",
    "    cri2 = ((1.0 /\n",
    "             (d_all.reflectance.sel(wl=510.0,\n",
    "                                    method='nearest') / 10000.0)\n",
    "            ) - \n",
    "            (1.0 /\n",
    "             (d_all.reflectance.sel(wl=700.0,\n",
    "                                    method='nearest') /\n",
    "              10000.0)\n",
    "            )\n",
    "           ).assign_coords(index='cri2').expand_dims('index')\n",
    "\n",
    "\n",
    "    d_all['indices'] = xr.concat(\n",
    "        [ndvi,\n",
    "         cai, \n",
    "         ndli, \n",
    "         mrendvi, \n",
    "         sipi, \n",
    "         cri1, \n",
    "         cri2],\n",
    "        dim='index').chunk((1.0,\n",
    "                            d_all.reflectance.data.chunksize[0],\n",
    "                            d_all.reflectance.data.chunksize[1])\n",
    "                          ).transpose('y','x','index').chunk(('auto','auto',1))\n",
    "\n",
    "    return d_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
